{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12201828,"sourceType":"datasetVersion","datasetId":7686045}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-18T05:58:59.583016Z","iopub.execute_input":"2025-06-18T05:58:59.583242Z","iopub.status.idle":"2025-06-18T05:59:01.033459Z","shell.execute_reply.started":"2025-06-18T05:58:59.583223Z","shell.execute_reply":"2025-06-18T05:59:01.032650Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/command-qa/command_qa.jsonl\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# !pip install -q transformers datasets accelerate peft bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T05:59:22.000176Z","iopub.execute_input":"2025-06-18T05:59:22.000801Z","iopub.status.idle":"2025-06-18T05:59:22.004157Z","shell.execute_reply.started":"2025-06-18T05:59:22.000772Z","shell.execute_reply":"2025-06-18T05:59:22.003452Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# !pip install bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T05:59:24.120998Z","iopub.execute_input":"2025-06-18T05:59:24.121297Z","iopub.status.idle":"2025-06-18T05:59:24.124935Z","shell.execute_reply.started":"2025-06-18T05:59:24.121276Z","shell.execute_reply":"2025-06-18T05:59:24.124310Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from datasets import load_dataset\n\ndata_path = \"/kaggle/input/command-qa/command_qa.jsonl\"\ndataset = load_dataset(\"json\", data_files=data_path, split=\"train\")\n\nprint(dataset[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:34:33.716127Z","iopub.execute_input":"2025-06-18T06:34:33.716924Z","iopub.status.idle":"2025-06-18T06:34:33.819748Z","shell.execute_reply.started":"2025-06-18T06:34:33.716897Z","shell.execute_reply":"2025-06-18T06:34:33.819061Z"}},"outputs":[{"name":"stdout","text":"{'instruction': \"How do I undo the most recent local commits in Git?\\n\\nI accidentally committed the wrong files to Git but haven't pushed the commit to the server yet.\\nHow do I undo those commits from the local repository?\", 'output': 'Undo a commit & redo\\n\\n```\\n$ git commit -m \"Something terribly misguided\" # (0: Your Accident)\\n$ git reset HEAD~                              # (1)\\n# === If you just want to undo the commit, stop here! ===\\n[ edit files as necessary ]                    # (2)\\n$ git add .                                    # (3)\\n$ git commit -c ORIG_HEAD                      # (4)\\n\\n```\\n\\n\\ngit reset is the command responsible for the undo. It will undo your last commit while leaving your working tree (the state of your files on disk) untouched. You\\'ll need to add them again before you can commit them again.\\nMake corrections to working tree files.\\ngit add anything that you want to include in your new commit.\\nCommit the changes, reusing the old commit message. reset copied the old head to .git/ORIG_HEAD; commit with -c ORIG_HEAD will open an editor, which initially contains the log message from the old commit and allows you to edit it. If you do not need to edit the message, you could use the -C option.\\n\\nAlternatively, to edit the previous commit (or just its commit message), commit --amend will add changes within the current index to the previous commit.\\nTo remove (not revert) a commit that has been pushed to the server, rewriting history with git push origin main --force[-with-lease] is necessary. It\\'s almost always a bad idea to use --force; prefer --force-with-lease instead, and as noted in the git manual:\\n\\nYou should understand the implications of rewriting history if you amend a commit that has already been published.\\n\\n\\nFurther Reading\\nYou can use git reflog to determine the SHA-1 for the commit to which you wish to revert. Once you have this value, use the sequence of commands as explained above.\\n\\nHEAD~ is the same as HEAD~1. The article What is the HEAD in git? is helpful if you want to uncommit multiple commits.'}\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"import re\nimport re\n\ndef clean_instruction(example):\n    text = example['instruction']\n    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n    text = \"\\n\".join(line.rstrip() for line in text.splitlines())\n    text = re.sub(r'[ \\t]{2,}', ' ', text)  # collapse tabs or multiple spaces\n    example['instruction'] = text.strip()\n    return example\n\n\ndataset_process = dataset.map(clean_instruction)\n\nprint(dataset_process[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:34:34.620779Z","iopub.execute_input":"2025-06-18T06:34:34.621035Z","iopub.status.idle":"2025-06-18T06:34:34.629910Z","shell.execute_reply.started":"2025-06-18T06:34:34.621016Z","shell.execute_reply":"2025-06-18T06:34:34.629359Z"}},"outputs":[{"name":"stdout","text":"{'instruction': \"How do I undo the most recent local commits in Git?\\n\\nI accidentally committed the wrong files to Git but haven't pushed the commit to the server yet.\\nHow do I undo those commits from the local repository?\", 'output': 'Undo a commit & redo\\n\\n```\\n$ git commit -m \"Something terribly misguided\" # (0: Your Accident)\\n$ git reset HEAD~                              # (1)\\n# === If you just want to undo the commit, stop here! ===\\n[ edit files as necessary ]                    # (2)\\n$ git add .                                    # (3)\\n$ git commit -c ORIG_HEAD                      # (4)\\n\\n```\\n\\n\\ngit reset is the command responsible for the undo. It will undo your last commit while leaving your working tree (the state of your files on disk) untouched. You\\'ll need to add them again before you can commit them again.\\nMake corrections to working tree files.\\ngit add anything that you want to include in your new commit.\\nCommit the changes, reusing the old commit message. reset copied the old head to .git/ORIG_HEAD; commit with -c ORIG_HEAD will open an editor, which initially contains the log message from the old commit and allows you to edit it. If you do not need to edit the message, you could use the -C option.\\n\\nAlternatively, to edit the previous commit (or just its commit message), commit --amend will add changes within the current index to the previous commit.\\nTo remove (not revert) a commit that has been pushed to the server, rewriting history with git push origin main --force[-with-lease] is necessary. It\\'s almost always a bad idea to use --force; prefer --force-with-lease instead, and as noted in the git manual:\\n\\nYou should understand the implications of rewriting history if you amend a commit that has already been published.\\n\\n\\nFurther Reading\\nYou can use git reflog to determine the SHA-1 for the commit to which you wish to revert. Once you have this value, use the sequence of commands as explained above.\\n\\nHEAD~ is the same as HEAD~1. The article What is the HEAD in git? is helpful if you want to uncommit multiple commits.'}\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"# for datast in range(len(dataset)):\n#     print(dataset[datast]['instruction'])\n\ntotal_length = 0\nmax_length = 0\n\nfor item in dataset_process:\n    instruction_length = len(item['instruction'])\n    total_length += instruction_length\n    if instruction_length > max_length:\n        max_length = instruction_length\n\naverage_length = total_length / len(dataset_process)\n\nprint(\"Max instruction length:\", max_length)\nprint(\"Average instruction length:\", average_length)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:34:36.352699Z","iopub.execute_input":"2025-06-18T06:34:36.352995Z","iopub.status.idle":"2025-06-18T06:34:36.395871Z","shell.execute_reply.started":"2025-06-18T06:34:36.352972Z","shell.execute_reply":"2025-06-18T06:34:36.395205Z"}},"outputs":[{"name":"stdout","text":"Max instruction length: 10245\nAverage instruction length: 604.3939818054583\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"total_length = 0\nmax_length = 0\n\nfor item in dataset_process:\n    output_length = len(item['output'])\n    total_length += output_length\n    if output_length > max_length:\n        max_length = output_length\n\naverage_length = total_length / len(dataset_process)\n\nprint(\"Max instruction length:\", max_length)\nprint(\"Average instruction length:\", average_length)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:34:36.536111Z","iopub.execute_input":"2025-06-18T06:34:36.536642Z","iopub.status.idle":"2025-06-18T06:34:36.579466Z","shell.execute_reply.started":"2025-06-18T06:34:36.536622Z","shell.execute_reply":"2025-06-18T06:34:36.578711Z"}},"outputs":[{"name":"stdout","text":"Max instruction length: 15203\nAverage instruction length: 896.0468859342197\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"# def tokenize(example):\n#     result = tokenizer(\n#         example[\"instruction\"],\n#         truncation=True,\n#         padding=\"max_length\",\n#         max_length=1024,\n#     )\n    \n#     result[\"labels\"] = result[\"input_ids\"].copy()\n#     return result\n\n# tokenized_dataset = dataset.map(tokenize, remove_columns=dataset.column_names)\n\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\ndef tokenize(example):\n    prompt = example[\"instruction\"].strip()\n    response = example[\"output\"].strip()\n\n    full_input = f\"{prompt}\\n\\n### Response:\\n{response}\"\n\n    result = tokenizer(\n        full_input,\n        truncation=True,\n        padding=\"max_length\",\n        max_length=1024,\n    )\n    result[\"labels\"] = result[\"input_ids\"].copy()\n    return result\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:34:38.766048Z","iopub.execute_input":"2025-06-18T06:34:38.766600Z","iopub.status.idle":"2025-06-18T06:34:38.898505Z","shell.execute_reply.started":"2025-06-18T06:34:38.766570Z","shell.execute_reply":"2025-06-18T06:34:38.897910Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"tokenized_dataset = dataset.map(tokenize, remove_columns=dataset.column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:34:41.441858Z","iopub.execute_input":"2025-06-18T06:34:41.442142Z","iopub.status.idle":"2025-06-18T06:34:43.898031Z","shell.execute_reply.started":"2025-06-18T06:34:41.442121Z","shell.execute_reply":"2025-06-18T06:34:43.897125Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1429 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c16cc87a6c3342d58f599617d077788e"}},"metadata":{}}],"execution_count":70},{"cell_type":"code","source":"tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:34:48.723063Z","iopub.execute_input":"2025-06-18T06:34:48.723754Z","iopub.status.idle":"2025-06-18T06:34:48.738072Z","shell.execute_reply.started":"2025-06-18T06:34:48.723713Z","shell.execute_reply":"2025-06-18T06:34:48.737211Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"tokenized_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:34:51.770517Z","iopub.execute_input":"2025-06-18T06:34:51.771066Z","iopub.status.idle":"2025-06-18T06:34:51.776327Z","shell.execute_reply.started":"2025-06-18T06:34:51.771043Z","shell.execute_reply":"2025-06-18T06:34:51.775449Z"}},"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 1286\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 143\n    })\n})"},"metadata":{}}],"execution_count":72},{"cell_type":"code","source":"tokenized_dataset['train'][0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nfrom peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\nimport torch\n\nbase_model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n\ntokenizer = AutoTokenizer.from_pretrained(base_model_id)\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model_id,\n    # load_in_4bit=True,\n    torch_dtype=torch.float16,\n    device_map={\"\": 1}\n)\nmodel = prepare_model_for_kbit_training(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:35:04.132968Z","iopub.execute_input":"2025-06-18T06:35:04.133243Z","iopub.status.idle":"2025-06-18T06:35:05.287049Z","shell.execute_reply.started":"2025-06-18T06:35:04.133223Z","shell.execute_reply":"2025-06-18T06:35:05.286193Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=32,\n    lora_alpha=64,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:35:05.827977Z","iopub.execute_input":"2025-06-18T06:35:05.828239Z","iopub.status.idle":"2025-06-18T06:35:05.939959Z","shell.execute_reply.started":"2025-06-18T06:35:05.828220Z","shell.execute_reply":"2025-06-18T06:35:05.939138Z"}},"outputs":[{"name":"stdout","text":"trainable params: 4,505,600 || all params: 1,104,553,984 || trainable%: 0.4079\n","output_type":"stream"}],"execution_count":75},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\nfrom transformers import DataCollatorForLanguageModeling\n\nimport torch\ntorch.cuda.set_device(0)\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False\n)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./qlora_tinyllama_cli\",\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    gradient_accumulation_steps=8,\n    num_train_epochs=1,\n    logging_steps=10,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-4,\n    fp16=True,\n    report_to=\"none\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    # label_names=[\"input_ids\", \"attention_mask\", \"labels\"]\n)\n\n\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:35:16.240179Z","iopub.execute_input":"2025-06-18T06:35:16.240976Z","iopub.status.idle":"2025-06-18T06:44:41.554276Z","shell.execute_reply.started":"2025-06-18T06:35:16.240948Z","shell.execute_reply":"2025-06-18T06:44:41.553706Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2899885126.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nNo label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [80/80 09:17, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.742600</td>\n      <td>1.749053</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=80, training_loss=1.7542819261550904, metrics={'train_runtime': 564.707, 'train_samples_per_second': 2.277, 'train_steps_per_second': 0.142, 'total_flos': 8171169911930880.0, 'train_loss': 1.7542819261550904, 'epoch': 0.995334370139969})"},"metadata":{}}],"execution_count":77},{"cell_type":"code","source":"trainer.save_model(\"./qlora_tinyllama_cli_final\")\ntokenizer.save_pretrained(\"./qlora_tinyllama_cli_final\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:44:49.198785Z","iopub.execute_input":"2025-06-18T06:44:49.199068Z","iopub.status.idle":"2025-06-18T06:44:49.395300Z","shell.execute_reply.started":"2025-06-18T06:44:49.199052Z","shell.execute_reply":"2025-06-18T06:44:49.394442Z"}},"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"('./qlora_tinyllama_cli_final/tokenizer_config.json',\n './qlora_tinyllama_cli_final/special_tokens_map.json',\n './qlora_tinyllama_cli_final/tokenizer.model',\n './qlora_tinyllama_cli_final/added_tokens.json',\n './qlora_tinyllama_cli_final/tokenizer.json')"},"metadata":{}}],"execution_count":78},{"cell_type":"code","source":"from transformers import pipeline\n\npipe = pipeline(\"text-generation\", model=\"./qlora_tinyllama_cli_final\", tokenizer=tokenizer, device=0)\nprompt = (\n    \"### Instruction:\\n\"\n    \"How can I delete a remote Git branch?\\n\\n\"\n    \"### Response:\\n\"\n)\n\noutput = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7)[0][\"generated_text\"]\nprint(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:48:25.768229Z","iopub.execute_input":"2025-06-18T06:48:25.768562Z","iopub.status.idle":"2025-06-18T06:48:37.151032Z","shell.execute_reply.started":"2025-06-18T06:48:25.768539Z","shell.execute_reply":"2025-06-18T06:48:37.150130Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"### Instruction:\nHow can I delete a remote Git branch?\n\n### Response:\nYou can use the git branch -D command to delete a branch from a remote repository. It is part of the git command line, and you can run it from the command line:\n\n```\ngit branch -D branch-name\n\n```\n\nIn this case, the branch is named branch-name.\nThe -D option is used to delete the branch.\nThe default behavior is to delete the branch and all the branch's refs (tracked and untracked).\n\nFor more information on deleting branches, see the git branch man page.\n\nHere is a sample response from a git pull command, which deletes a branch and leaves it in the remote repository:\n\n```\n$ git push origin :branch-name\n\n```\n\nNote that you may need to specify the remote (git clone) and the branch you want to delete (branch-name).\n\nFor more information on deleting branches, see the git branch man page.\n\nHere is a sample response from a git push command, which deletes a branch but leaves it in the remote repository:\n\n```\n$ git push origin :branch-name --delete\n\n```\n\nNote that you may need to specify the remote\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"output = pipe(prompt, max_new_tokens=200, do_sample=False)[0][\"generated_text\"]\nprint(output[len(prompt):].strip())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:50:02.385817Z","iopub.execute_input":"2025-06-18T06:50:02.386122Z","iopub.status.idle":"2025-06-18T06:50:08.833078Z","shell.execute_reply.started":"2025-06-18T06:50:02.386100Z","shell.execute_reply":"2025-06-18T06:50:08.832247Z"}},"outputs":[{"name":"stdout","text":"You can use the git branch -d command to delete a remote branch.\n\n```\ngit branch -d branch_name\n\n```\n\nThis will delete the branch and all its commits.\n\n```\ngit branch -d branch_name\n\n```\n\nThis will delete the branch and all its commits, including any local branches that are forked from it.\n\n```\ngit branch -d branch_name --delete\n\n```\n\nThis will delete the branch and all its commits, including any local branches that are forked from it.\n\n```\ngit branch -d branch_name --delete\n\n```\n\nThis will delete the branch and all its commits, including any local branches that are forked from it.\n\n```\ngit branch -d branch_name --delete\n\n```\n\nThis will delete the branch and all its commits, including any local branches that are forked from it.\n\n```\ngit\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"response = output[len(prompt):].strip()\nprint(response)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:48:45.631804Z","iopub.execute_input":"2025-06-18T06:48:45.632564Z","iopub.status.idle":"2025-06-18T06:48:45.637164Z","shell.execute_reply.started":"2025-06-18T06:48:45.632537Z","shell.execute_reply":"2025-06-18T06:48:45.636409Z"}},"outputs":[{"name":"stdout","text":"You can use the git branch -D command to delete a branch from a remote repository. It is part of the git command line, and you can run it from the command line:\n\n```\ngit branch -D branch-name\n\n```\n\nIn this case, the branch is named branch-name.\nThe -D option is used to delete the branch.\nThe default behavior is to delete the branch and all the branch's refs (tracked and untracked).\n\nFor more information on deleting branches, see the git branch man page.\n\nHere is a sample response from a git pull command, which deletes a branch and leaves it in the remote repository:\n\n```\n$ git push origin :branch-name\n\n```\n\nNote that you may need to specify the remote (git clone) and the branch you want to delete (branch-name).\n\nFor more information on deleting branches, see the git branch man page.\n\nHere is a sample response from a git push command, which deletes a branch but leaves it in the remote repository:\n\n```\n$ git push origin :branch-name --delete\n\n```\n\nNote that you may need to specify the remote\n","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"!zip -r /kaggle/working/qlora_tinyllama_cli_final.zip /kaggle/working/qlora_tinyllama_cli_final","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:51:38.157912Z","iopub.execute_input":"2025-06-18T06:51:38.158857Z","iopub.status.idle":"2025-06-18T06:51:39.575434Z","shell.execute_reply.started":"2025-06-18T06:51:38.158830Z","shell.execute_reply":"2025-06-18T06:51:39.574644Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/qlora_tinyllama_cli_final/ (stored 0%)\n  adding: kaggle/working/qlora_tinyllama_cli_final/adapter_model.safetensors","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 8%)\n  adding: kaggle/working/qlora_tinyllama_cli_final/tokenizer.json (deflated 85%)\n  adding: kaggle/working/qlora_tinyllama_cli_final/training_args.bin (deflated 52%)\n  adding: kaggle/working/qlora_tinyllama_cli_final/README.md (deflated 66%)\n  adding: kaggle/working/qlora_tinyllama_cli_final/tokenizer.model (deflated 55%)\n  adding: kaggle/working/qlora_tinyllama_cli_final/tokenizer_config.json (deflated 68%)\n  adding: kaggle/working/qlora_tinyllama_cli_final/adapter_config.json (deflated 53%)\n  adding: kaggle/working/qlora_tinyllama_cli_final/special_tokens_map.json (deflated 73%)\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:52:11.967650Z","iopub.execute_input":"2025-06-18T06:52:11.968448Z","iopub.status.idle":"2025-06-18T06:52:40.495829Z","shell.execute_reply.started":"2025-06-18T06:52:11.968412Z","shell.execute_reply":"2025-06-18T06:52:40.495199Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [72/72 00:28]\n    </div>\n    "},"metadata":{}},{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 1.7490533590316772,\n 'eval_runtime': 28.5155,\n 'eval_samples_per_second': 5.015,\n 'eval_steps_per_second': 2.525,\n 'epoch': 0.995334370139969}"},"metadata":{}}],"execution_count":84},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}