{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T05:59:22.000801Z",
     "iopub.status.busy": "2025-06-18T05:59:22.000176Z",
     "iopub.status.idle": "2025-06-18T05:59:22.004157Z",
     "shell.execute_reply": "2025-06-18T05:59:22.003452Z",
     "shell.execute_reply.started": "2025-06-18T05:59:22.000772Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install -q transformers datasets accelerate peft bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T05:59:24.121297Z",
     "iopub.status.busy": "2025-06-18T05:59:24.120998Z",
     "iopub.status.idle": "2025-06-18T05:59:24.124935Z",
     "shell.execute_reply": "2025-06-18T05:59:24.124310Z",
     "shell.execute_reply.started": "2025-06-18T05:59:24.121276Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T06:34:33.716924Z",
     "iopub.status.busy": "2025-06-18T06:34:33.716127Z",
     "iopub.status.idle": "2025-06-18T06:34:33.819748Z",
     "shell.execute_reply": "2025-06-18T06:34:33.819061Z",
     "shell.execute_reply.started": "2025-06-18T06:34:33.716897Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': \"How do I undo the most recent local commits in Git?\\n\\nI accidentally committed the wrong files to Git but haven't pushed the commit to the server yet.\\nHow do I undo those commits from the local repository?\", 'output': 'Undo a commit & redo\\n\\n```\\n$ git commit -m \"Something terribly misguided\" # (0: Your Accident)\\n$ git reset HEAD~                              # (1)\\n# === If you just want to undo the commit, stop here! ===\\n[ edit files as necessary ]                    # (2)\\n$ git add .                                    # (3)\\n$ git commit -c ORIG_HEAD                      # (4)\\n\\n```\\n\\n\\ngit reset is the command responsible for the undo. It will undo your last commit while leaving your working tree (the state of your files on disk) untouched. You\\'ll need to add them again before you can commit them again.\\nMake corrections to working tree files.\\ngit add anything that you want to include in your new commit.\\nCommit the changes, reusing the old commit message. reset copied the old head to .git/ORIG_HEAD; commit with -c ORIG_HEAD will open an editor, which initially contains the log message from the old commit and allows you to edit it. If you do not need to edit the message, you could use the -C option.\\n\\nAlternatively, to edit the previous commit (or just its commit message), commit --amend will add changes within the current index to the previous commit.\\nTo remove (not revert) a commit that has been pushed to the server, rewriting history with git push origin main --force[-with-lease] is necessary. It\\'s almost always a bad idea to use --force; prefer --force-with-lease instead, and as noted in the git manual:\\n\\nYou should understand the implications of rewriting history if you amend a commit that has already been published.\\n\\n\\nFurther Reading\\nYou can use git reflog to determine the SHA-1 for the commit to which you wish to revert. Once you have this value, use the sequence of commands as explained above.\\n\\nHEAD~ is the same as HEAD~1. The article What is the HEAD in git? is helpful if you want to uncommit multiple commits.'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_path = \"/kaggle/input/command-qa/command_qa.jsonl\"\n",
    "dataset = load_dataset(\"json\", data_files=data_path, split=\"train\")\n",
    "\n",
    "print(dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T06:34:34.621035Z",
     "iopub.status.busy": "2025-06-18T06:34:34.620779Z",
     "iopub.status.idle": "2025-06-18T06:34:34.629910Z",
     "shell.execute_reply": "2025-06-18T06:34:34.629359Z",
     "shell.execute_reply.started": "2025-06-18T06:34:34.621016Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': \"How do I undo the most recent local commits in Git?\\n\\nI accidentally committed the wrong files to Git but haven't pushed the commit to the server yet.\\nHow do I undo those commits from the local repository?\", 'output': 'Undo a commit & redo\\n\\n```\\n$ git commit -m \"Something terribly misguided\" # (0: Your Accident)\\n$ git reset HEAD~                              # (1)\\n# === If you just want to undo the commit, stop here! ===\\n[ edit files as necessary ]                    # (2)\\n$ git add .                                    # (3)\\n$ git commit -c ORIG_HEAD                      # (4)\\n\\n```\\n\\n\\ngit reset is the command responsible for the undo. It will undo your last commit while leaving your working tree (the state of your files on disk) untouched. You\\'ll need to add them again before you can commit them again.\\nMake corrections to working tree files.\\ngit add anything that you want to include in your new commit.\\nCommit the changes, reusing the old commit message. reset copied the old head to .git/ORIG_HEAD; commit with -c ORIG_HEAD will open an editor, which initially contains the log message from the old commit and allows you to edit it. If you do not need to edit the message, you could use the -C option.\\n\\nAlternatively, to edit the previous commit (or just its commit message), commit --amend will add changes within the current index to the previous commit.\\nTo remove (not revert) a commit that has been pushed to the server, rewriting history with git push origin main --force[-with-lease] is necessary. It\\'s almost always a bad idea to use --force; prefer --force-with-lease instead, and as noted in the git manual:\\n\\nYou should understand the implications of rewriting history if you amend a commit that has already been published.\\n\\n\\nFurther Reading\\nYou can use git reflog to determine the SHA-1 for the commit to which you wish to revert. Once you have this value, use the sequence of commands as explained above.\\n\\nHEAD~ is the same as HEAD~1. The article What is the HEAD in git? is helpful if you want to uncommit multiple commits.'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import re\n",
    "\n",
    "def clean_instruction(example):\n",
    "    text = example['instruction']\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    text = \"\\n\".join(line.rstrip() for line in text.splitlines())\n",
    "    text = re.sub(r'[ \\t]{2,}', ' ', text)  # collapse tabs or multiple spaces\n",
    "    example['instruction'] = text.strip()\n",
    "    return example\n",
    "\n",
    "\n",
    "dataset_process = dataset.map(clean_instruction)\n",
    "\n",
    "print(dataset_process[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T06:34:36.352995Z",
     "iopub.status.busy": "2025-06-18T06:34:36.352699Z",
     "iopub.status.idle": "2025-06-18T06:34:36.395871Z",
     "shell.execute_reply": "2025-06-18T06:34:36.395205Z",
     "shell.execute_reply.started": "2025-06-18T06:34:36.352972Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max instruction length: 10245\n",
      "Average instruction length: 604.3939818054583\n"
     ]
    }
   ],
   "source": [
    "# for datast in range(len(dataset)):\n",
    "#     print(dataset[datast]['instruction'])\n",
    "\n",
    "total_length = 0\n",
    "max_length = 0\n",
    "\n",
    "for item in dataset_process:\n",
    "    instruction_length = len(item['instruction'])\n",
    "    total_length += instruction_length\n",
    "    if instruction_length > max_length:\n",
    "        max_length = instruction_length\n",
    "\n",
    "average_length = total_length / len(dataset_process)\n",
    "\n",
    "print(\"Max instruction length:\", max_length)\n",
    "print(\"Average instruction length:\", average_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T06:34:36.536642Z",
     "iopub.status.busy": "2025-06-18T06:34:36.536111Z",
     "iopub.status.idle": "2025-06-18T06:34:36.579466Z",
     "shell.execute_reply": "2025-06-18T06:34:36.578711Z",
     "shell.execute_reply.started": "2025-06-18T06:34:36.536622Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max instruction length: 15203\n",
      "Average instruction length: 896.0468859342197\n"
     ]
    }
   ],
   "source": [
    "total_length = 0\n",
    "max_length = 0\n",
    "\n",
    "for item in dataset_process:\n",
    "    output_length = len(item['output'])\n",
    "    total_length += output_length\n",
    "    if output_length > max_length:\n",
    "        max_length = output_length\n",
    "\n",
    "average_length = total_length / len(dataset_process)\n",
    "\n",
    "print(\"Max instruction length:\", max_length)\n",
    "print(\"Average instruction length:\", average_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T06:34:38.766600Z",
     "iopub.status.busy": "2025-06-18T06:34:38.766048Z",
     "iopub.status.idle": "2025-06-18T06:34:38.898505Z",
     "shell.execute_reply": "2025-06-18T06:34:38.897910Z",
     "shell.execute_reply.started": "2025-06-18T06:34:38.766570Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def tokenize(example):\n",
    "#     result = tokenizer(\n",
    "#         example[\"instruction\"],\n",
    "#         truncation=True,\n",
    "#         padding=\"max_length\",\n",
    "#         max_length=1024,\n",
    "#     )\n",
    "    \n",
    "#     result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "#     return result\n",
    "\n",
    "# tokenized_dataset = dataset.map(tokenize, remove_columns=dataset.column_names)\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "def tokenize(example):\n",
    "    prompt = example[\"instruction\"].strip()\n",
    "    response = example[\"output\"].strip()\n",
    "\n",
    "    full_input = f\"{prompt}\\n\\n### Response:\\n{response}\"\n",
    "\n",
    "    result = tokenizer(\n",
    "        full_input,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=1024,\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T06:34:41.442142Z",
     "iopub.status.busy": "2025-06-18T06:34:41.441858Z",
     "iopub.status.idle": "2025-06-18T06:34:43.898031Z",
     "shell.execute_reply": "2025-06-18T06:34:43.897125Z",
     "shell.execute_reply.started": "2025-06-18T06:34:41.442121Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16cc87a6c3342d58f599617d077788e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1429 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize, remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T06:34:48.723754Z",
     "iopub.status.busy": "2025-06-18T06:34:48.723063Z",
     "iopub.status.idle": "2025-06-18T06:34:48.738072Z",
     "shell.execute_reply": "2025-06-18T06:34:48.737211Z",
     "shell.execute_reply.started": "2025-06-18T06:34:48.723713Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T06:34:51.771066Z",
     "iopub.status.busy": "2025-06-18T06:34:51.770517Z",
     "iopub.status.idle": "2025-06-18T06:34:51.776327Z",
     "shell.execute_reply": "2025-06-18T06:34:51.775449Z",
     "shell.execute_reply.started": "2025-06-18T06:34:51.771043Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1286\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 143\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenized_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T06:35:04.133243Z",
     "iopub.status.busy": "2025-06-18T06:35:04.132968Z",
     "iopub.status.idle": "2025-06-18T06:35:05.287049Z",
     "shell.execute_reply": "2025-06-18T06:35:05.286193Z",
     "shell.execute_reply.started": "2025-06-18T06:35:04.133223Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "import torch\n",
    "\n",
    "base_model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    # load_in_4bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map={\"\": 1}\n",
    ")\n",
    "model = prepare_model_for_kbit_training(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T06:35:05.828239Z",
     "iopub.status.busy": "2025-06-18T06:35:05.827977Z",
     "iopub.status.idle": "2025-06-18T06:35:05.939959Z",
     "shell.execute_reply": "2025-06-18T06:35:05.939138Z",
     "shell.execute_reply.started": "2025-06-18T06:35:05.828220Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,505,600 || all params: 1,104,553,984 || trainable%: 0.4079\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T06:35:16.240976Z",
     "iopub.status.busy": "2025-06-18T06:35:16.240179Z",
     "iopub.status.idle": "2025-06-18T06:44:41.554276Z",
     "shell.execute_reply": "2025-06-18T06:44:41.553706Z",
     "shell.execute_reply.started": "2025-06-18T06:35:16.240948Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/2899885126.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 09:17, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.742600</td>\n",
       "      <td>1.749053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80, training_loss=1.7542819261550904, metrics={'train_runtime': 564.707, 'train_samples_per_second': 2.277, 'train_steps_per_second': 0.142, 'total_flos': 8171169911930880.0, 'train_loss': 1.7542819261550904, 'epoch': 0.995334370139969})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "import torch\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qlora_tinyllama_cli\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    # label_names=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T06:44:49.199068Z",
     "iopub.status.busy": "2025-06-18T06:44:49.198785Z",
     "iopub.status.idle": "2025-06-18T06:44:49.395300Z",
     "shell.execute_reply": "2025-06-18T06:44:49.394442Z",
     "shell.execute_reply.started": "2025-06-18T06:44:49.199052Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./qlora_tinyllama_cli_final/tokenizer_config.json',\n",
       " './qlora_tinyllama_cli_final/special_tokens_map.json',\n",
       " './qlora_tinyllama_cli_final/tokenizer.model',\n",
       " './qlora_tinyllama_cli_final/added_tokens.json',\n",
       " './qlora_tinyllama_cli_final/tokenizer.json')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./qlora_tinyllama_cli_final\")\n",
    "tokenizer.save_pretrained(\"./qlora_tinyllama_cli_final\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T06:48:25.768562Z",
     "iopub.status.busy": "2025-06-18T06:48:25.768229Z",
     "iopub.status.idle": "2025-06-18T06:48:37.151032Z",
     "shell.execute_reply": "2025-06-18T06:48:37.150130Z",
     "shell.execute_reply.started": "2025-06-18T06:48:25.768539Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "How can I delete a remote Git branch?\n",
      "\n",
      "### Response:\n",
      "You can use the git branch -D command to delete a branch from a remote repository. It is part of the git command line, and you can run it from the command line:\n",
      "\n",
      "```\n",
      "git branch -D branch-name\n",
      "\n",
      "```\n",
      "\n",
      "In this case, the branch is named branch-name.\n",
      "The -D option is used to delete the branch.\n",
      "The default behavior is to delete the branch and all the branch's refs (tracked and untracked).\n",
      "\n",
      "For more information on deleting branches, see the git branch man page.\n",
      "\n",
      "Here is a sample response from a git pull command, which deletes a branch and leaves it in the remote repository:\n",
      "\n",
      "```\n",
      "$ git push origin :branch-name\n",
      "\n",
      "```\n",
      "\n",
      "Note that you may need to specify the remote (git clone) and the branch you want to delete (branch-name).\n",
      "\n",
      "For more information on deleting branches, see the git branch man page.\n",
      "\n",
      "Here is a sample response from a git push command, which deletes a branch but leaves it in the remote repository:\n",
      "\n",
      "```\n",
      "$ git push origin :branch-name --delete\n",
      "\n",
      "```\n",
      "\n",
      "Note that you may need to specify the remote\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"./qlora_tinyllama_cli_final\", tokenizer=tokenizer, device=0)\n",
    "prompt = (\n",
    "    \"### Instruction:\\n\"\n",
    "    \"How can I delete a remote Git branch?\\n\\n\"\n",
    "    \"### Response:\\n\"\n",
    ")\n",
    "\n",
    "output = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7)[0][\"generated_text\"]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T06:50:02.386122Z",
     "iopub.status.busy": "2025-06-18T06:50:02.385817Z",
     "iopub.status.idle": "2025-06-18T06:50:08.833078Z",
     "shell.execute_reply": "2025-06-18T06:50:08.832247Z",
     "shell.execute_reply.started": "2025-06-18T06:50:02.386100Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can use the git branch -d command to delete a remote branch.\n",
      "\n",
      "```\n",
      "git branch -d branch_name\n",
      "\n",
      "```\n",
      "\n",
      "This will delete the branch and all its commits.\n",
      "\n",
      "```\n",
      "git branch -d branch_name\n",
      "\n",
      "```\n",
      "\n",
      "This will delete the branch and all its commits, including any local branches that are forked from it.\n",
      "\n",
      "```\n",
      "git branch -d branch_name --delete\n",
      "\n",
      "```\n",
      "\n",
      "This will delete the branch and all its commits, including any local branches that are forked from it.\n",
      "\n",
      "```\n",
      "git branch -d branch_name --delete\n",
      "\n",
      "```\n",
      "\n",
      "This will delete the branch and all its commits, including any local branches that are forked from it.\n",
      "\n",
      "```\n",
      "git branch -d branch_name --delete\n",
      "\n",
      "```\n",
      "\n",
      "This will delete the branch and all its commits, including any local branches that are forked from it.\n",
      "\n",
      "```\n",
      "git\n"
     ]
    }
   ],
   "source": [
    "output = pipe(prompt, max_new_tokens=200, do_sample=False)[0][\"generated_text\"]\n",
    "print(output[len(prompt):].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T06:48:45.632564Z",
     "iopub.status.busy": "2025-06-18T06:48:45.631804Z",
     "iopub.status.idle": "2025-06-18T06:48:45.637164Z",
     "shell.execute_reply": "2025-06-18T06:48:45.636409Z",
     "shell.execute_reply.started": "2025-06-18T06:48:45.632537Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can use the git branch -D command to delete a branch from a remote repository. It is part of the git command line, and you can run it from the command line:\n",
      "\n",
      "```\n",
      "git branch -D branch-name\n",
      "\n",
      "```\n",
      "\n",
      "In this case, the branch is named branch-name.\n",
      "The -D option is used to delete the branch.\n",
      "The default behavior is to delete the branch and all the branch's refs (tracked and untracked).\n",
      "\n",
      "For more information on deleting branches, see the git branch man page.\n",
      "\n",
      "Here is a sample response from a git pull command, which deletes a branch and leaves it in the remote repository:\n",
      "\n",
      "```\n",
      "$ git push origin :branch-name\n",
      "\n",
      "```\n",
      "\n",
      "Note that you may need to specify the remote (git clone) and the branch you want to delete (branch-name).\n",
      "\n",
      "For more information on deleting branches, see the git branch man page.\n",
      "\n",
      "Here is a sample response from a git push command, which deletes a branch but leaves it in the remote repository:\n",
      "\n",
      "```\n",
      "$ git push origin :branch-name --delete\n",
      "\n",
      "```\n",
      "\n",
      "Note that you may need to specify the remote\n"
     ]
    }
   ],
   "source": [
    "response = output[len(prompt):].strip()\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T06:51:38.158857Z",
     "iopub.status.busy": "2025-06-18T06:51:38.157912Z",
     "iopub.status.idle": "2025-06-18T06:51:39.575434Z",
     "shell.execute_reply": "2025-06-18T06:51:39.574644Z",
     "shell.execute_reply.started": "2025-06-18T06:51:38.158830Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/qlora_tinyllama_cli_final/ (stored 0%)\n",
      "  adding: kaggle/working/qlora_tinyllama_cli_final/adapter_model.safetensors"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (deflated 8%)\n",
      "  adding: kaggle/working/qlora_tinyllama_cli_final/tokenizer.json (deflated 85%)\n",
      "  adding: kaggle/working/qlora_tinyllama_cli_final/training_args.bin (deflated 52%)\n",
      "  adding: kaggle/working/qlora_tinyllama_cli_final/README.md (deflated 66%)\n",
      "  adding: kaggle/working/qlora_tinyllama_cli_final/tokenizer.model (deflated 55%)\n",
      "  adding: kaggle/working/qlora_tinyllama_cli_final/tokenizer_config.json (deflated 68%)\n",
      "  adding: kaggle/working/qlora_tinyllama_cli_final/adapter_config.json (deflated 53%)\n",
      "  adding: kaggle/working/qlora_tinyllama_cli_final/special_tokens_map.json (deflated 73%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /kaggle/working/qlora_tinyllama_cli_final.zip /kaggle/working/qlora_tinyllama_cli_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T06:52:11.968448Z",
     "iopub.status.busy": "2025-06-18T06:52:11.967650Z",
     "iopub.status.idle": "2025-06-18T06:52:40.495829Z",
     "shell.execute_reply": "2025-06-18T06:52:40.495199Z",
     "shell.execute_reply.started": "2025-06-18T06:52:11.968412Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.7490533590316772,\n",
       " 'eval_runtime': 28.5155,\n",
       " 'eval_samples_per_second': 5.015,\n",
       " 'eval_steps_per_second': 2.525,\n",
       " 'epoch': 0.995334370139969}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7686045,
     "sourceId": 12201828,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
